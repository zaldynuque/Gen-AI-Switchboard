# -*- coding: utf-8 -*-
"""Virtual_Data_Science_(1) (2)_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vb59DGEVZcwyFYcqkEFgaDCFLWD1uI34

## **Business Context**

Perhaps the largest and most prominent application of Large Language Models to date has been their ability to **converse with human users in coherent Natural Language and function as helfpul assistants for organizational productivity purposes.** As we know by now, a lot of work goes into creating and providing such Assistant-style LLMs to us as a service - the hugely compute-expensive Supervised Pre-training stage that's responsible for the vast majority of the LLM's world knowledge, the Instruction-style Supervised Fine-tuning stage on curated dialog datasets that adapts the LLM's behavior to that of a high-quality assistant, and the RLHF stage that teaches the LLM to provide responses that are aligned with human values. **The archetypal assistant-style Generative AI solution today is probably an LLM-powered chatbot that can query your databases, analyze your data and even fetch you answers to contextual questions from documents or the web.**

**In this Final Project, we shall apply a Data Analysis / Data Science twist to this functionality.** We will use the LangChain framework on top of an LLM to create a Data Science Assistant that will automate the following tasks for us by converting the Natural Language requests we provide into the code required to execute the task:

1. **Data Analysis**

2. **Data Science & Machine Learning Modeling**

3. **Relational Database Querying**

4. **Retrieval-Augmented Generation for Contextual Answers**

There are obvious reasons why such a project could be highly significant to business / research. By automating the code tasks common to various operations in Data Analysis, Data Science or Database Querying, such a solution has the potential to save significant time, improve code accuracy and also open up Data Analysis and Data Science to a more general audience that may not be familiar with the code involved.

From a broader perspective, the newfound ability of the best Large Language Models (beyond 1 billion parameters) to understand the true meaning of Natural Language commands and coherently respond to, acknowledge and fulfill them, has enabled us to usher in the next wave in the long list of automations that Computer Science has seen in its history. Translating commands into programming code, once solely the province of human developers, is now increasingly being automated by Generative AI, and we'll see many examples of the same in this project.


## **Project Objective**

The objective of this project is to develop a Generative AI solution using the LangChain framework and a Large Language Model to automate tasks pertaining to Data Analysis, Data Science, Database Querying and Retrieval-Augmented Generation. This will be broken down into several sub-tasks, each of which will automatically be performed by our Large Language Model purely by prompting it in the right direction.

## **I. Setting up the Environment**

### **Write a pip install function for the following libraries that we will require in this project**

### **openai, pandas, matplotlib, seaborn, cohere, tiktoken,**
### **langchain_experimental, pypdf, faiss-gpu, google-search-results**
"""

# Use pip to install all dependencies here
# You will need to use the specified versions of openai and langchain dependencies for the smooth working of the project as mentioned below:
# openai==1.7.1 langchain_experimental==0.0.49 langchain==0.1.0 langchain-core==0.1.10

# Installing the required libraries
!pip install tiktoken;
!pip install openai==1.21.2;
!pip install pypdf;
!pip install faiss-gpu;
!pip install google-search-results;
!pip install cohere;
!pip install pandas;
!pip install matplotlib;
!pip install seaborn;
!pip install langchain_experimental==0.0.57 langchain==0.1.16 langchain-core==0.1.44;
!pip install langchain-openai

# Displaying the OpenAI, Langchain, and Langchain Experimental library version
!pip3 show openai;
!pip3 show langchain;
!pip3 show langchain_experimental;

"""### **Importing the libraries into the notebook**"""

# Importing libraries
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
# from langchain.llms import OpenAI
# from langchain.chat_models import ChatOpenAI
from langchain_openai import OpenAI, ChatOpenAI
from langchain.sql_database import SQLDatabase
from langchain.llms import HuggingFacePipeline
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.llms import HuggingFaceHub
from langchain.document_loaders import PyPDFLoader
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.agents.agent_toolkits import create_conversational_retrieval_agent
from langchain.agents.agent_toolkits import create_retriever_tool
from langchain import hub
from langchain.schema.runnable import RunnablePassthrough
from langchain.agents import load_tools
import sqlite3

"""## **II. LLM Setup**

### **Add the API Key & OPENAI_API_BASE from the Great Learning Olympus Platform**
"""

# Importing the GPT-4 LLM and setting it up
API_KEY = 'Use your own key'
OPENAI_API_BASE = 'https://api.openai.com/v1/'

# API_KEY = 'Use your own key'
# OPENAI_API_BASE = 'https://aibe.mygreatlearning.com/openai/v1/'

os.environ['OPENAI_API_KEY'] = API_KEY
os.environ['OPENAI_API_BASE'] = OPENAI_API_BASE

"""### **Add the name of the GPT-4 model that we will use as the LLM for the LangChain Assistant**"""

# This is our LLM, the heart of the entire process. Here we are using the GPT-4 Model from OpenAi.
# model_name = 'gpt-4-turbo-2024-04-09'
model_name = 'gpt-3.5-turbo-0125'
llm = ChatOpenAI(temperature=0, model=model_name)

"""## **Creating an EDA Agent**

**We shall first be initializing a Pandas Dataframe Agent below.**

*What is an agent?*
It can be thought of as an interface with a variety of tools chained together. First do this, then do that ...

These tools are defined by users as prompts to the LLM. Connecting an agent with a LLM simply brings these tools into the arsenal of the LLM, enabling it to use them.
The role of the user is to provide the LLM with the tools through prompts, while the LLM is responsible for deciding which tools it must use depending on the user input.

Another thing to observe is that there can be as many agents as tools that you might create. So, an agent could search the web, could fetch weather data, could perform calculations, or even do Machine Learning.

Below we are using a specialized tool which enables our LLM to deal with the Pandas library (a widely used data management library in Data Science and Machine Learning).

## **III. Reading in the File and Counting the Number of Rows in the DataFrame**

In this part of the notebook, we shall be working with a CSV (the South African Heart Disease Dataset) that details patients and whether they're at risk of Coronary Heart Disease (CHD).

### **Use the read_csv() function to import the South Africa Heart Disease CSV dataset provided**
"""

# Importing the structured data
df = pd.read_csv('https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data');

"""### **Initialize a DataFrame Agent of the Pandas library in LangChain**"""

# Initializing the DataFrame agent of the Pandas library in LangChain allows our LLM to work with
# Pandas DataFrames with simple, natural language commands
agent = create_pandas_dataframe_agent(
    llm,
    df,
    verbose=True,
    agent_type=AgentType.OPENAI_FUNCTIONS,
)

"""Let's now start getting to know our data with some basic questions.

### **Write a user query prompt to ask the agent how many rows the DataFrame contains, and run the agent command**
"""

# .run enables us to pass a query into the agent and see its output
# Determine how many rows the DataFrame contains
text = 'How many rows are there?';
res = agent.invoke(text);
print(res)

"""In the code above, we aim to store our question in the `text` variable.

Then we simply `run` the agent with this question.

What this does is, it forwards this question to our LLM, and lets it decide:

"for this user question give me a response. Use pandas if you have to"

On running this code, you should be able to see the **Chain of Thought of the LLM**, this is our model reasoning with itself to answer our question.

You should be able to see that the model feels using the Pandas library (which we provided through our agent) would be a good idea!

## **IV. Obtaining Simple Information about the DataFrame**

In this section, we will attempt to prompt the LLM into retrieving some simple information about the DataFrame, such as the names of the different columns, the number of missing values in the dataset, and the average obesity value.

### **Find out the names of the different columns present in this dataset**
"""

# Find out the names of the different columns present in this dataset
text = 'How many different columns are there in the dataset? What are the names of these columns?';
res = agent.invoke(text);
print(res)

"""### **Find out how many missing values are present in the dataset**"""

# Determine how many missing values are present in the dataset
text = 'Are there any missing values in the dataset?';
res = agent.invoke(text);
print(res)

"""### **Compute the average obesity value**"""

# Compute the average obesity value
text = 'What is the average obesity value in the dataset?';
res = agent.invoke(text);
print(res)

"""## **V. Obtaining a Brief Summary of the Columns in the Dataset**

### **Obtain a brief summary of the columns present in the dataset**
"""

# Display a brief summary of the columns in the dataset
text = 'Can you display a brief summary of the columns in the dataset for me?'
res = agent.invoke(text);
print(res)

"""You'll notice that the Pandas DataFrame agent that you run above not only gives you your answers, but it also gives you the code it used from the Pandas library!

## **Getting the EDA Agent to perform Plotting**

Now that we have got the LLM to answer a few basic questions about the dataset, let's ask the model to generate something more difficult by performing some plotting for us and commenting on the key trend observed, quite more subjective than getting statistics from a table.

- Let us get the model to **generate a KDE plot** for us for to help us find the relation between obesity and risk of heart disease. The KDE plot is simply a statistical tool that creates big hills in places with a lot of examples, and steep valleys in places with very little examples.

- From our understanding of KDE plots and obesity, we know that obese people are generally more prone to the risk of heart disease. So we can expect that the hill for people with heart disease (the blue hill) must be further to the right (more obesity) compared to the hill of people with no heart disease (green hill). Let's see if this is what we get.

## **VI. Creating a KDE Plot of obsesity among people with CHD and without CHD**

### **Instruct the model to generate a KDE plot of obesity among people with / without CHD.**

### **Be sure to ask the model to label both axes and add a legend, and also ask the model to comment on the trend which the plot uncovers**
"""

# Here we will show the ability of the model to create a plot and comment on the underlying trend in the data
# Generate a KDE plot of obesity among people with / without CHD
text = 'Generate a Kernel Density Estimation (KDE) plot of obesity among people with / without Coronary Heart Disease (CHD). Label the axes, add a legend, and comment on the main trends.';
res = agent.invoke(text);
print(res)

"""## **VII. Creating a distribution of age of people with respect to CHD**

### **Instruct the model to show the distribution of age of people with respect to CHD.**

### **Ensure the model labels the axes, and comments on the principal trend observed**
"""

# Show the distribution of age of people with respect to CHD
text = 'Show the distribution of age of people with respect to Coronary Heart Disease (CHD). Label the axes, and comment on the principal trend observed.';
res = agent.invoke(text);
print(res)

"""Let us now try to see how the various factors contributing towards heart dieases are related to each other. We can do this by plotting a heatmap where the darker colored tiles would mean that the factors corresponding to the row and column position of that tile are more heavily correlated, and lighter colors would show a lighter correlation.

## **VIII. Creating a Pairwise Correlation Heatmap**

### **Instruct the model to display a heatmap to show the correlation between all the columns.**

### **Ensure the axes are labeled and the model highlights the standout trends**
"""

# Display a heatmap to show the correlation between all the columns
text = 'Plot a correlation heatmap, showing correlations among all the columns. Label the axes, and highlight the standout trends.';
res = agent.invoke(text);
print(res)

"""Alright, so as we see, our model is quite good at plotting requests and finding the underlying trends.

Let's see if it can go to the next level and also test out hypothesese for us.

## **Hypothesis Testing**

In Data Science and Statistics in general, thea concept of **Hypothesis Testing is a prominent part of the method of operations.**

Hypothesis Testing is just a fancy term for **statistically fact-checking a quantitative claim.**

We pose a particular claim (an alternate hypothesis) and we pose a null claim (a claim which says that our hypothesis is useless). After this we take several examples and see whether they follow our claim or not with a degree of assurance so that those results could not have occurred by chance.

In the example below, we follow the following structure:

**Claim:** Obesity increases the risk of heart disease

Now we would use the following steps:
- On average, what is the obsesity level of people with heart disease and without heart disease ?
- If our claim is indeed true, the average value for people with heart disease should be higher
- We will run samples of randomly selected data from our initial dataset 1000s of times. We will then see what the distribution of the averages looks like.
- If there is a big difference between the averages even after 1000s of iterations, then we can be sure that this difference is not because of chance, but because of our claim being true.

## **IX. Running a Hypothesis Test to check the effects of obesity on the likelihood of CHD**

### **Write a prompt to ask the model to perform a statistical t-Test to validate the following hypotheses:**

### **Null Hypothesis:** Higher levels of obesity do not increase the risk of CHD.

### **Alternate Hypothesis:** Higher levels of obesity increase the risk of CHD.
"""

# Let's use a t-value Hypothesis Test to check whether obesity affects the chances of CHD
text = 'Validate the following hypothesis using a T-test. Null Hypothesis: Higher levels of obesity do not increase the risk of CHD. Alternate Hypothesis: Higher levels of obesity increase the risk of CHD.';
res = agent.invoke(text);
print(res)

"""## **Machine Learning Modeling using LLMs**

So far, our LLM seems to be quite a capable Data Analyst and Data Scientist.

Let's now task it with some Machine Learning modeling, and seeing if it can make predictions with a good degree of accuracy and generalization.

- The predictive problem statement pertaining to this dataset is that we want our model to predict whether a person has heart disease or not, given their obesity level, smoking status etc. (all the other columns from our data set).
- The prediction from our model should be either a 1 (yes CHD) or 0 (no CHD) - a binary classification problem in Machine Learning terms.
- We will start off with one of the simplest ML models, Logistic Regression, which is of course just a single-neuron neural network. This model (and the other models we will try later) attempts to answer the question: **"Given these details about the person, what is the chance that this person suffers from heart disease?"**

## **X. Building a Logistic Regression Model**

### **Write a detailed step-by-step prompt requesting the model to create a Logistic Regression model using the steps common to the ML workflow, such as cleaning the dataset, preprocessing it, splitting the data into Train and Test, training the model on the Train dataset and making predictions on the Test dataset. The model should print out the accuracy score it obtains on the Test dataset.**
"""

# Get the LLM agent to perform Logistic Regression modeling
fixed_model_prompt = 'Follow these steps to run a Logistic Regression model to predict the CHD variable:\
1. Clean the dataset so it has no null values.\
2. Preprocess the dataset so it is ready for use by a Logistic Regression model.\
3. Run Logistic Regression to classify people into 1 (with CHD) or 0 (without CHD) with the following steps:\
3a. Split the data into Train and Test sets. These datasets should not contain the CHD column.\
3b. Train the model on the Train dataset. Make sure the model converges, so use as many iterations as necessary for that.\
3c. Obtain y_pred by predicting on X_test and use a threshold to convert y_pred into binary values.\
3d. Plot the Confusion Matrix, print the accuracy score between binary y_pred and y_test, and comment on the predictive performance of the model.'

res = agent.invoke(fixed_model_prompt);
print(res)

"""Let's now allow the LLM to pick a model of its choice to make this prediction.

## **XI. Binary Classification with an ML Model of the LLM's Choice**

### **Write a similar detailed step-by-step prompt to the above, this time requesting the LLM to run a Binary Classification model of its choice from a list of options we give it, such as Decision Trees, Random Forests, XGBoost, Support Vector Machines, Neural Network, etc. The LLM has to provide reasoning for why it picked this model. Otherwise, the rest of the steps can be similar to the prompt drafted for the earlier question.**
"""

# Allow the LLM agent to pick a model of its choice to make this prediction
variable_model_prompt = 'Follow these steps to run a Binary Classification model of your choice from a list of options such as Decision Trees, Random Forests, XGBoost, and Support Vector Machines to predict the CHD variable:\
1. Clean the dataset so it has no null values.\
2. Preprocess the dataset so it is ready for use by the Binary Classification models.\
3. Run Binary Classification to classify people into 1 (with CHD) or 0 (without CHD) with the following steps:\
3a. Split the data into Train and Test sets. These datasets should not contain the CHD column.\
3b. Train the model on the Train dataset. Make sure the model converges, so use as many iterations as necessary for that.\
3c. Obtain y_pred by predicting on X_test and use a threshold to convert y_pred into binary values.\
3d. Plot the Confusion Matrix, print the accuracy score between binary y_pred and y_test, and comment on the predictive performance of the model.\
4. Compare the performance of each model, pick the best performing model and provide reasoning for why the model was selected.'

agent.run(variable_model_prompt);

"""Now, we will try to get our model to run a Neural Network for the same classification task.

## **XII. Binary Classification with a Neural Network**

### **In this version of the prompt, instruct the LLM to run a binary classification Neural Network using TensorFlow or PyTorch to predict whether people have CHD or not. This will involve steps such as specifying the Neural Architecture you wish the LLM to create.**
"""

# Remember to be as precise in your instructions as possible. This just helps to reduce the probability of the model mis-interpreting our commands
nn_model_prompt = 'Follow these steps to run a Binary Classification Neural Network to predict the CHD variable:\
1. Clean the dataset so it has no null values.\
2. Preprocess the dataset so it is ready for use by a Binary Classification Neural Network.\
3. Run Binary Classification to classify people into 1 (with CHD) or 0 (without CHD) with the following steps:\
3a. Define the model architecture:\
3.a.1. Three hidden layers with ReLU as activation function.\
3.a.2. Dropout = 0.5.\
3.a.3. Optimizer = adam.\
3.a.4. Loss = binary_crossentropy.\
3.a.5. Metrics = [accuracy].\
3.a.6. Epochs = 30.\
3.a.7. Batch Size = 32.\
3b. Split the dataset into training, validation, and test sets (80% training, 10% validation, 10% test). These datasets should not contain the CHD column.\
3c. Train the model on the Train dataset. Make sure the model converges, so use as many iterations as necessary for that.\
3d. Predict the model on the Test dataset to see how the binary classification Neural Network generalized on unseen data.\
3d. Obtain y_pred by predicting on X_test and use a threshold to convert y_pred into binary values.\
3e. Plot the Confusion Matrix, print the accuracy score between binary y_pred and y_test, and comment on the predictive performance of the model.'

agent.run(nn_model_prompt);

"""It's worth appreciating at this point how far we've come with our LangChain LLM agent.

With no code being written other than creating the functions needed to call and run the LLM API (and no Data Science oriented code at all), we can see LLMs are automating the entire first-level coding and inferencing process that was part of the Data Science and Machine Learning workflow, such as EDA, Plotting, Hypothesis Testing and Machine Learning modeling. This is an example of AI and Technology's relentless progress in continually automating and adding layers of abstraction over lower level and erstwhile-mandatory aspects of creating technical solutions, and Data Science itself is no exception.

Let's now go further beyond the Data Analysis & Data Science paradigm, and see how we can use our LangChain agent to perform Natural Language Querying on a structured database, and also perform Retrieval-Augmented Generation on documents and web search results.

## **XIII. Database Natural Language Querying**

In this section, we will focus on creating a new agent with our LLM.

This agent will carry out 2 main tasks for us:

- **Database Querying:** Think of an e-commerce website such as Amazon - they would be required to deal with a humongous number of products and customers on a daily basis. They likely store all this information in a large database - and being able to query and retrieve relevant information from that database is critical for their operations to work. This is done through queries and requests, SQL queries in particular for relational databases. We shall now ask our agent to do this for us on a toy dataset.

- **Math:** Secondly, we will also equip our agent with another tool - math. Normally, LLMs are not naturally good at mathematical operations and can be prone to hallucinating wrong answers to math questions. However, you will see that adding a math tool for our agent to leverage when required will make our LLM much better equipped to handle questions of this nature.

First, we'll import the sub-packages we need:
"""

from langchain.agents import *
from langchain.sql_database import SQLDatabase
from langchain.llms import HuggingFacePipeline

"""In the following code block, we will be creating a toy SQL database using SQLite for demonstration purposes."""

# Creating a dummy SQL database for our example.
conn = sqlite3.connect('sample.db')

# Creating a cursor object to interact with the database
cursor = conn.cursor()

# Creating a table to store employee information
cursor.execute('''
    CREATE TABLE IF NOT EXISTS Employees (
        EmployeeID INTEGER PRIMARY KEY,
        FirstName TEXT,
        LastName TEXT,
        Birthdate DATE,
        Department TEXT,
        Salary REAL
    )
''')

# Inserting some sample data into the Employees table
cursor.executemany('''
    INSERT INTO Employees (FirstName, LastName, Birthdate, Department, Salary)
    VALUES (?, ?, ?, ?, ?)
''', [
    ('John', 'Doe', '1990-05-15', 'HR', 50000.00),
    ('Jane', 'Smith', '1985-12-10', 'Sales', 55000.00),
    ('Bob', 'Johnson', '1992-08-25', 'Engineering', 60000.00),
    ('Alice', 'Brown', '1988-04-03', 'Marketing', 52000.00)
])

# Commiting the changes and close the connection
conn.commit()
conn.close()

"""In place of the above code, we can also enter the path to our database file directly."""

# In place of file, you can enter the path to your database file
file = "sample.db"
db = SQLDatabase.from_uri(f"sqlite:///{file}")

"""Now let's create our Database Agent and equip it with the LLM math tool."""

tools = ['llm-math']

tools = load_tools(tools,llm)

toolkit = SQLDatabaseToolkit(db=db, llm=llm)
db_agent = create_sql_agent(
    llm=llm,
    toolkit=toolkit,
    tools=tools,
    verbose=True
)

"""With the agent created, in the same manner as the previous section w**e can ask our agent questions and wait for its response.**

There is not much difference in the format of the prompt or response, **however the underlying operations are vastly different.**

### **Write a prompt to ask the Database Agent to name the columns present in the database, and then run that prompt with the `db_agent` defined above**
"""

# Naming the columns present in the database
prompt = 'Please list all the columns present in the Employees table within the sample database'
db_agent.run(prompt);

"""### **Write a prompt to ask the Database Agent what was the maximum salary paid to an employee, and to whom it was paid**"""

# Retrieving the maximum salary and who received it
prompt = 'Could you provide the details of the highest salary paid, including the amount and the name of the employee who received it?'
db_agent.run(prompt);

"""Let's now give the agent a chance to use its math tool with an arithmetic question.

### **Write a prompt to ask the Database Agent to compute the square root of the maximum salary paid to an employee**
"""

# Let's see if our LLM is profecient at arithemtic with the help of its math tool
prompt = 'Could you calculate the square root of the highest salary paid to any employee?'
db_agent.run(prompt);

"""## **XIV. Retrieval-Augmented Generation**

**In this section, we will perform Retrieval-Augmented Generation (RAG) with a LangChain agent.** As we know, RAG refers to the process of supplementing the context of an LLM from the System Prompt and User Query, with additional chunks of text that may have been retrieved from external sources such as a Document or the results of a Web Search. This additional context is used by the LLM to generate what usually turns out to be a much more contextual and relevant answer to the User Query, especially when that query refers to current news or specific facts or figures that may not have been present in the LLM's original pre-training dataset. **The benefits of augmenting an LLM's capability with RAG are numerous**, such as providing it with additional knowledge, reducing its risk of hallucination, and being able to now fact-check the LLM by monitoring the sources from which it has generated its answer.

- What we shall do here is, we shall first load our document, split it into easy to handle chunks, and then vectorize and store these chunks in a Vector Database
- We provide our RAG Agent with this Vector Database and a few more tools
- Whenever we ask the agent a question, it will refer to the document to find something from the database which could answer our question
- So if you asked it to summarise a chapter from the book, the agent would first fetch the specific chapter from the database and then summarise it with the LLM

Let's now see the agent in action.
"""

from langchain.agents.agent_toolkits import create_retriever_tool

"""We shall import a chapter from an Operating Systems course book."""

# Let's create an object to load the book
Loader = PyPDFLoader('https://pages.cs.wisc.edu/~remzi/OSTEP/cpu-intro.pdf')

"""Next, we shall load the document and split it into several chunks, each of size 1000 and with an overlap of 50 between chunks."""

# We use the loader created above to load the document
documents = Loader.load()

# We split the document into several chunks as mentioned above
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
texts = text_splitter.split_documents(documents)

"""Let's vectorize these chunks into vector embeddings, and store them in the FAISS Vector Database."""

# Now we transform these chunks into the list of number called vectors and store them into our database
embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(texts, embeddings)

"""Now, we create a Retriever instance that will perform similarity search and extract those vector chunks relevant to the user query."""

# We create a retreiver instance. Its job is to fetch for us a vector (portion of the document) relevant to the user
# question
retriever = db.as_retriever()

"""Finally, we shall write the prompt to create the RAG agent."""

# This is the prompt to create a RAG agent for us
retriever_name = "search_the_text_of_pdf"
retriever_desc = """The purpose of this tool is to answer questions based on the book: 'Operating Systems 3 \
easy pieces' regarding operating systems in computer science. Answer any query input by the user from the vectorbase\
if you do not know the answer, then use the serpapi tool to search the web for the answer. Clearly state that you\
searched the web. Keep your answers short and precise."""

"""We are defining two tools below:

1. **RAG Tool:** This is the tool that performs RAG for us on the loaded document. It needs access to the retreiver object that we created above to fetch relevant pieces from our database to answer our questions.

2. **Serpapi Tool:** In case the LLM is unable to find an answer for some question from the document that we uploaded, one option is to tell you that it did not find any relevant answer from the document, so it would need to search the internet to give you an answer. The Serpapi tool searches Google for the result.
"""

rag_tool = create_retriever_tool(
    retriever,
    retriever_name,
    retriever_desc
)

#os.environ['SERPAPI_API_KEY'] = '4bde37c74068633153b825cb3ff392ee3a6697a630674d5abb5d55be50f58a49'
os.environ['SERPAPI_API_KEY'] = '65253bc1f78bc03af233f810685a26194fce02fb5aa0a526abb501edbea0588a'
search_tool = load_tools(['serpapi'])
tools = [rag_tool, search_tool[0]] # we can have multiple tools, hence the list

RAG_executor = create_conversational_retrieval_agent(llm=llm, tools=tools, verbose=True) # setting verbose=True to output the thought process of the agent

"""Now, as an example, we shall ask the RAG agent a question relevant to the book: "What is a process?"

The model correctly calls the search_document tool to fetch us the answer to our question.
"""

question = "what is a process"
user_query = {"input": question}
result = RAG_executor(user_query)
print(f"Result: {result['output']}")

"""### **Repeat the above code flow to ask the agent "What are the different states of a process?"**"""

question = 'What are the different states of a process?'
user_query = {"input": question }
result = RAG_executor(user_query)
print(f"Result: {result['output']}")

"""Let's now ask the other kind of question, where the answer to the question may not be present in the PDF document, so the agent has to recognize that and turn to the Search tool to search the web and find a possible answer from there.

### **Repeat the flow to ask the agent "Who is the current president of the United States?"**
"""

question = 'Who is the current president of the United States?'
user_query = {"input": question }
result = RAG_executor(user_query)
print(f"Result: {result['output']}")

"""### **Ask the agent to find out "Who is the CEO of Microsoft?"**"""

question = 'Who is the CEO of Microsoft?'
user_query = {"input": question }
result = RAG_executor(user_query)
print(f"Result: {result['output']}")

"""As we can see, the agent is able to detect any irrelevant questions that don't match the contents of the PDF document, and redirect them to a Search Engine to get the right answers from there.

This concludes our simple demonstration of the various capabilities of LangChain Agent Assistants through this Final Project notebook.

## **XV. Conclusions and Recommendations**

### **What are your conclusions from the exercise of utilizing LangChain Agents as Data Science Assistants or Retriever Assistants in this manner? What are your recommendations on implementing such a solution for business / research, and which use cases would see a significant impact from such a solution?**

## **Conclusions and Recommendations**

**Conclusions:**
 * **Capability to Filter Irrelevant Queries:** The LangChain Agent demonstrated the ability to identify questions that do not align with the contents of a specific document. In such cases, it redirected these queries to a search engine to fetch appropriate answers from external sources.

 * **Demonstration of Diverse Functionalities**: Through various exercises in the project, the LangChain Agent showcased its capabilities in assisting with data science tasks, effectively acting as a bridge between the user's questions and the relevant data or information, whether it be contained within a given document or requiring external retrieval.

**Recommendations for Implementation:**
The following recommendations can be inferred for businesses and research environments:

 * **Integrate with Knowledge Repositories:** For businesses and research institutions with vast internal knowledge bases or document repositories, integrating LangChain Agents can enhance information retrieval and decision-making processes by providing precise, context-aware information extraction and retrieval.

 * **Augment Research Capabilities:** Researchers can leverage these agents to sift through extensive literature, extract pertinent information, and even identify knowledge gaps by querying external databases seamlessly.

 * **Enhance Business Intelligence:** In business environments, these agents can be employed to analyze reports, financial documents, and market research, offering quick insights and responses to strategic queries by tapping into both internal and external data sources.

 * **Customer Support Enhancement:** LangChain Agents could significantly improve customer support systems by providing accurate, context-sensitive information drawn from product manuals, FAQs, and external knowledge bases, reducing response times and improving customer satisfaction.

**Impactful Use Cases:**

 * **Academic Research:** Streamlining literature review and data extraction processes.

 * **Market Analysis:** Rapid analysis of market trends and competitor information from diverse sources.

 * **Healthcare:** Quick retrieval of patient information, research findings, and treatment guidelines from medical records and research papers.

 * **Legal Research:** Efficient search and analysis of legal documents, case laws, and precedents.

 * **Grid Management and Monitoring:** In the utilities sector, LangChain Agents can analyze data from smart grids and IoT devices to predict load demands, identify potential failures or inefficiencies, and suggest optimizations, contributing to more reliable and efficient utility services.

 * **Customer Service and Engagement:** By analyzing customer queries, feedback, and interaction patterns, LangChain Agents can provide personalized assistance and advice to utility customers, improving satisfaction and engagement.

 * **Sustainability and Environmental Impact Analysis:** Utilities companies can use these agents to collect and analyze data on environmental impacts, energy consumption patterns, and sustainability practices, helping to inform policies and practices that reduce environmental footprints and promote sustainable energy use.

 * **Product Development and Innovation:** LangChain Agents can assist in researching and aggregating the latest trends, technologies, and methodologies from a wide array of sources, helping R&D teams stay ahead of the curve and innovate more effectively.

 * **Technical Support and Troubleshooting**: By integrating these agents with technical documentation, knowledge bases, and forums, companies can offer more efficient and accurate support to both internal teams and end-users, reducing resolution times for technical issues.

 * **Software Development and Code Review:** LangChain Agents can be trained to assist in code review processes by retrieving best practices, documentation, and relevant snippets from a vast repository of coding resources, thereby enhancing code quality and developer productivity.

These recommendations and use cases suggest a broad applicability of LangChain Agents as assistants in data-intensive environments, offering significant benefits in terms of efficiency, accuracy, and depth of analysis.
"""